{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "j72nrfvnzk5hvawcngeq",
   "authorId": "6276428134692",
   "authorName": "TANU_D_GUPTA",
   "authorEmail": "",
   "sessionId": "1231c89f-2d5f-433f-8a86-ef4168c59392",
   "lastEditTime": 1750946431639
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nimport numpy as np\nimport altair as alt\nimport plotly.express as px\n#from tabulate import tabulate\n#from sklearn.decomposition import PCA\n#import matplotlib.pyplot as plt\n#import seaborn as sns\n#from sklearn.ensemble import RandomForestClassifier\n#from sklearn.model_selection import train_test_split\n#from sklearn.metrics import classification_report\n\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "--create or replace stage my_python_packages_stage;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "# Then, we can use the python name to turn cell2 into a Pandas dataframe\n#my_df = cell2.to_pandas()\n\n# Chart the data\n#st.subheader(\"Chance of SNOW ‚ùÑÔ∏è\")\n#st.line_chart(my_df, x='SNOWDAY', y='CHANCE_OF_SNOW')\n\n# Give it a go!\n#st.subheader(\"Try it out yourself and show off your skills ü•á\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7edc876b-a493-44df-9c26-071afb3f0a88",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": "-- Summary of constructor based on points, number of laps done by each driver\nselect c.name as constructorname,sum(rs.points) as Total_Points ,SUM(laps) as Total_Laps ,count(d.driverid) as Total_Drivers,\nfrom \nplayground.datathon.results rs\nleft join playground.datathon.races rc on rs.raceid = rc.raceid\nleft join playground.datathon.drivers d on rs.driverid = d.driverid\nleft join playground.datathon.constructors c on rs.constructorid = c.constructorid\nleft join playground.datathon.status s on rs.statusid = s.statusid\nwhere UPPER(s.status) = 'FINISHED'\ngroup by c.name\norder by sum(rs.points) desc;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b63b792-06fb-4df7-b790-03078e6085d9",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "dg5_df = cell4.to_pandas()\n\n# Chart the data\nst.subheader(\"Constructor Summary - Points based\")\nchart = alt.Chart(dg5_df).mark_bar().encode(\n    x=alt.X('CONSTRUCTORNAME:N',sort='-y'),\n    y='TOTAL_POINTS:Q'\n)\nst.altair_chart(chart, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85fa32fb-cdcd-4128-8978-239175844a53",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "dg5_df = cell4.to_pandas()\n\n# Chart the data\nst.subheader(\"Constructor Summary - Laps based\")\nchart = alt.Chart(dg5_df).mark_bar().encode(\n    x=alt.X('CONSTRUCTORNAME:N',sort='-y'),\n    y='TOTAL_LAPS:Q'\n)\nst.altair_chart(chart, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "21060930-f766-4e66-a905-01d484b336d8",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": "SELECT s.status\n, CASE WHEN RS.POSITION IS NULL THEN '99' ELSE RS.POSITION END AS POSITION\n, CASE WHEN RS.MILLISECONDS IS NULL THEN '0' ELSE RS.MILLISECONDS END AS MILLISECONDS\n, RS.*\nFROM PLAYGROUND.DATATHON.RACES rc\nleft join playground.datathon.RESULTS rs on rs.raceid = rc.raceid\nleft join playground.datathon.status s on rs.statusid = s.statusid\nWHERE RS.POSITION IS NULL OR RS.MILLISECONDS IS NULL\nLIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d973f949-784a-4d7c-b87f-a67d2e648f38",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": "SELECT rc.NAME as RACE,rc.YEAR,rc.ROUND,rc.CIRCUITID,C.NAME AS CONSTRUCTOR,CONCAT(D.FORENAME,' ',D.SURNAME) AS DRIVER,RS.LAPS,S.STATUS,RS.POSITION,RS.MILLISECONDS\nFROM PLAYGROUND.DATATHON.RACES rc\nleft join playground.datathon.RESULTS rs on rs.raceid = rc.raceid\nleft join playground.datathon.status s on rs.statusid = s.statusid\nleft join playground.datathon.constructors c on rs.constructorid = c.constructorid\nleft join playground.datathon.drivers d on rs.driverid = d.driverid",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22a19e4a-101f-496a-b024-ab87ae3aa948",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "#Cleanse the data by removing the missing values\ndg5_df1 = cell9.to_pandas()\ndg5_df1 = dg5_df1.dropna()\n\ntable=tabulate(dg5_df1.values,headers=dg5_df1.columns,tablefmt='grid')\n\ndg5_df1.to_csv(\"C:\\\\Users\\\\tanu.d.gupta\\\\OneDrive - Accenture\\\\Documents\\\\Tanu\\\\Personal\\\\Datathon 2025\\\\clean_races.csv\")\n\n#print(table)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2cceb746-92c3-4872-80dd-b2df706426a7",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "# Handle missing values\ndg5_df1 = cell9.to_pandas()\n\n#for col in dg5_df1.columns:\n#    if dg5_df1[col].dtype in ['int64','float64']:\n#        dg5_df1[col].fillna(99,inplace=True)\n#    elif dg5_df1[col].dtype in ['datetime64','date64']:\n#        dg5_df1[col].fillna('9999-12-31',inplace=True)\n#    else:\n#            dg5_df1[col].fillna('DEF',inplace=True)\n#table=tabulate(dg5_df1.values,headers=dg5_df1.columns,tablefmt='grid')\n\n#print(table)\n\n# Drop rows with missing values in key columns\n#dg5_df.dropna(subset=['RACEID', 'YEAR', 'RESULTID', 'CONSTRUCTORID','DRIVERID'], inplace=True)\n\n# Convert to correct types\n#dg5_df['pole_gap'] = dg5_df['pole_gap'].astype(float)\n#dg5_df['lap_time'] = dg5_df['lap_time'].astype(float)\n\n# Encode categorical features\n#df = pd.get_dummies(dg5_df, columns=['location'], drop_first=True)\n\n# Save clean dataset\n#df.to_csv('cleaned_race_data.csv', index=False)\n\n\n\n\n# Histograms (this gives us a quick diagnostic of data‚Äîsuch as whether values are skewed, normally distributed, or have outliers.)\ndg5_df1.hist(bins=20, figsize=(10, 6))\nplt.suptitle(\"Feature Distributions\")\nplt.tight_layout()\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "153af9c5-9679-4f09-9c5e-a46dc0963b1e",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "dg5_df2 = cell9.to_pandas()\n\n# Prepare data\nX = dg5_df2.drop('STATUS', axis=1)\ny = dg5_df2['STATUS']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train model\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)",
   "execution_count": null
  }
 ]
}